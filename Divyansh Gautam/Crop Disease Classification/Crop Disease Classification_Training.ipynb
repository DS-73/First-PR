{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Crop Disease Classification_Training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1C2TJktoMwh72h8h-sS3lk92UtY8pCkCl","authorship_tag":"ABX9TyM5MXTTgWO1+idOdCRNYmwM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Data Preparation**"],"metadata":{"id":"8GXRHX21zi8m"}},{"cell_type":"code","source":["import pandas as pd\n","import os\n","import shutil"],"metadata":{"id":"UlMnEMUYzL1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Crop Disease Recognition/Dataset/class.csv')\n","data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zELI5R-gzRyS","executionInfo":{"status":"ok","timestamp":1639752466109,"user_tz":-330,"elapsed":768,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"a3431bd3-9078-48e9-cc44-4623b67ac578"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1821 entries, 0 to 1820\n","Data columns (total 5 columns):\n"," #   Column             Non-Null Count  Dtype \n","---  ------             --------------  ----- \n"," 0   image_id           1821 non-null   object\n"," 1   healthy            1821 non-null   int64 \n"," 2   multiple_diseases  1821 non-null   int64 \n"," 3   rust               1821 non-null   int64 \n"," 4   scab               1821 non-null   int64 \n","dtypes: int64(4), object(1)\n","memory usage: 71.3+ KB\n"]}]},{"cell_type":"code","source":["data.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"id":"Hsmnn2_dzVVY","executionInfo":{"status":"ok","timestamp":1639752466110,"user_tz":-330,"elapsed":14,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"200bf840-086a-40ea-a5ac-5d1417247cd9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-b21c18cd-2652-421d-985b-05e055e0e906\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_id</th>\n","      <th>healthy</th>\n","      <th>multiple_diseases</th>\n","      <th>rust</th>\n","      <th>scab</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Train_0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Train_1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Train_2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Train_3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Train_4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Train_5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Train_6</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Train_7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Train_8</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Train_9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b21c18cd-2652-421d-985b-05e055e0e906')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b21c18cd-2652-421d-985b-05e055e0e906 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b21c18cd-2652-421d-985b-05e055e0e906');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  image_id  healthy  multiple_diseases  rust  scab\n","0  Train_0        0                  0     0     1\n","1  Train_1        0                  1     0     0\n","2  Train_2        1                  0     0     0\n","3  Train_3        0                  0     1     0\n","4  Train_4        1                  0     0     0\n","5  Train_5        1                  0     0     0\n","6  Train_6        0                  1     0     0\n","7  Train_7        0                  0     0     1\n","8  Train_8        0                  0     0     1\n","9  Train_9        1                  0     0     0"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Checking no. of samples for each class\n","\n","print(\"healthy: \", data['healthy'].value_counts()[1])\n","print(\"multiple_diseases: \", data['multiple_diseases'].value_counts()[1])\n","print(\"rust: \", data['rust'].value_counts()[1])\n","print(\"scab: \", data['scab'].value_counts()[1])\n","\n","# Total: 1821\n","# \tHealthy: 516\n","# \tMultiple: 91\n","# \tRust: 622\n","# \tScab: 592\n","\n","# Train: 1458\n","# \tHealthy: 413\n","# \tMultiple: 73\n","# \tRust: 498\n","# \tScab: 474\n","\t\n","# Test: 183\n","# \tHealthy: 52\n","# \tMultiple: 10\n","# \tRust: 62\n","# \tScab: 59\n","\n","# Validation: 180\n","# \tHealthy: 51\n","# \tMultiple: 8\n","# \tRust: 62\n","# \tScab: 59"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dk6a3K1GzZh1","executionInfo":{"status":"ok","timestamp":1639752466110,"user_tz":-330,"elapsed":12,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"650e86ce-bddd-486b-a0ab-51f9441aea6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["healthy:  516\n","multiple_diseases:  91\n","rust:  622\n","scab:  592\n"]}]},{"cell_type":"code","source":["# Categorizing images into classes\n","\n","classes = ['healthy', 'multiple_diseases', 'rust', 'scab']\n","data_path = '/content/drive/MyDrive/Crop Disease Recognition/Dataset/'\n","dest_path = '/content/drive/MyDrive/Crop Disease Recognition/Dataset/Splits/'\n","\n","try:\n","    os.mkdir(dest_path + 'Categorized')\n","\n","    for c in classes:\n","        os.mkdir(os.path.join(dest_path, 'Categorized', c))\n","\n","    imgs = os.listdir(data_path + 'Images/')\n","\n","    for img in imgs:\n","        for i in range(len(data)):\n","            if img[:-4] == data.iloc[i]['image_id']:\n","                shutil.copyfile(os.path.join(data_path, 'Images', img), os.path.join(dest_path, 'Categorized', data.columns[data.iloc[i] == 1][0], img))\n","                break\n","except:\n","    print(\"!! Directory already exists !!\")"],"metadata":{"id":"OQt1zjLkzfxw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Model Training**"],"metadata":{"id":"wxKyXhGSzuHe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2aQn4cZkqZaa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639738516085,"user_tz":-330,"elapsed":1302,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"e41a1a6d-b0c7-4da1-c75e-22c43679c2cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 0s 0us/step\n","58900480/58889256 [==============================] - 0s 0us/step\n"]}],"source":["# Using pre-trained weights of VGG16 architecture\n","\n","from keras.applications import vgg16\n","img_rows, img_cols = 224, 224\n","VGG = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols,3))"]},{"cell_type":"code","source":["# Freezing trained layers\n","\n","for layer in VGG.layers:\n","    layer.trainable = False"],"metadata":{"id":"p4S0HHohqgxc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building layers in CNN\n","\n","def top(bottom_model, num_classes):\n","    top_model = bottom_model.output\n","    top_model = GlobalAveragePooling2D()(top_model)\n","    top_model = Dense(1024,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(512,activation='relu')(top_model)\n","    top_model = Dense(256,activation='relu')(top_model)\n","    top_model = Dense(128,activation='relu')(top_model)\n","    top_model = Dense(num_classes,activation='softmax')(top_model)\n","    return top_model"],"metadata":{"id":"3IkRIe2kuqTG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n","from keras.layers import BatchNormalization\n","from keras.models import Model\n","\n","num_classes = 4\n","\n","FC_Head = top(VGG, num_classes)\n","\n","model = Model(inputs = VGG.input, outputs = FC_Head)\n","\n","print(model.summary())"],"metadata":{"id":"t6MbI7sZuqfY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639583328441,"user_tz":-330,"elapsed":820,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"20b4e9cc-8c47-409d-f1c9-1fed0d76f8b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," global_average_pooling2d_1   (None, 512)              0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," dense_6 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," dense_7 (Dense)             (None, 512)               524800    \n","                                                                 \n"," dense_8 (Dense)             (None, 512)               262656    \n","                                                                 \n"," dense_9 (Dense)             (None, 256)               131328    \n","                                                                 \n"," dense_10 (Dense)            (None, 128)               32896     \n","                                                                 \n"," dense_11 (Dense)            (None, 4)                 516       \n","                                                                 \n","=================================================================\n","Total params: 16,192,196\n","Trainable params: 1,477,508\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_data_dir = '/content/drive/MyDrive/Crop Disease Recognition/Dataset/Splits/train'\n","validation_data_dir = '/content/drive/MyDrive/Crop Disease Recognition/Dataset/Splits/validation'\n"," \n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","batch_size = 64\n"," \n","train_generator = train_datagen.flow_from_directory(\n","        train_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')\n"," \n","validation_generator = validation_datagen.flow_from_directory(\n","        validation_data_dir,\n","        target_size=(img_rows, img_cols),\n","        batch_size=batch_size,\n","        class_mode='categorical')"],"metadata":{"id":"8izoddd7uw8I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639738549044,"user_tz":-330,"elapsed":479,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}},"outputId":"f8cce6bc-0b87-407b-962a-beaaf90b499d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1253 images belonging to 4 classes.\n","Found 180 images belonging to 4 classes.\n"]}]},{"cell_type":"code","source":["# Training the model\n","\n","from tensorflow.keras.optimizers import RMSprop\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","                  \n","checkpoint = ModelCheckpoint(\"crop_disease.h5\",\n","                             monitor=\"val_loss\",\n","                             mode=\"min\",\n","                             save_best_only = True,\n","                             verbose=1)\n","\n","earlystop = EarlyStopping(monitor = 'val_loss', \n","                          min_delta = 0, \n","                          patience = 3,\n","                          verbose = 1,\n","                          restore_best_weights = True)\n","\n","callbacks = [earlystop, checkpoint]\n"," \n","model.compile(loss = 'categorical_crossentropy',\n","              optimizer = RMSprop(lr = 0.001),\n","              metrics = ['accuracy'])\n","\n","nb_train_samples = 1253\n","nb_validation_samples = 180\n"," \n","epochs = 10\n","batch_size = 64\n","\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch = nb_train_samples // batch_size,\n","    epochs = epochs,\n","    callbacks = callbacks,\n","    validation_data = validation_generator,\n","    validation_steps = nb_validation_samples // batch_size)"],"metadata":{"id":"4aTe7Ma2xzW2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4d22559e-79ed-46fa-f248-e5b1c663ee53","executionInfo":{"status":"ok","timestamp":1639590146574,"user_tz":-330,"elapsed":4059780,"user":{"displayName":"Divyansh Gautam","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYPeoKwjjl6Aq_X6f1mtTFNfS6l75YT_UHqcHLrQ=s64","userId":"02820810417475771207"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(RMSprop, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","19/19 [==============================] - ETA: 0s - loss: 1.2873 - accuracy: 0.3768 \n","Epoch 00001: val_loss improved from inf to 1.22396, saving model to crop_disease.h5\n","19/19 [==============================] - 758s 39s/step - loss: 1.2873 - accuracy: 0.3768 - val_loss: 1.2240 - val_accuracy: 0.3516\n","Epoch 2/10\n","19/19 [==============================] - ETA: 0s - loss: 1.2327 - accuracy: 0.4029 \n","Epoch 00002: val_loss improved from 1.22396 to 1.17712, saving model to crop_disease.h5\n","19/19 [==============================] - 740s 39s/step - loss: 1.2327 - accuracy: 0.4029 - val_loss: 1.1771 - val_accuracy: 0.4531\n","Epoch 3/10\n","19/19 [==============================] - ETA: 0s - loss: 1.2533 - accuracy: 0.4340 \n","Epoch 00003: val_loss did not improve from 1.17712\n","19/19 [==============================] - 734s 39s/step - loss: 1.2533 - accuracy: 0.4340 - val_loss: 1.2057 - val_accuracy: 0.4141\n","Epoch 4/10\n","19/19 [==============================] - ETA: 0s - loss: 1.1511 - accuracy: 0.4844 \n","Epoch 00004: val_loss improved from 1.17712 to 1.07006, saving model to crop_disease.h5\n","19/19 [==============================] - 730s 39s/step - loss: 1.1511 - accuracy: 0.4844 - val_loss: 1.0701 - val_accuracy: 0.5547\n","Epoch 5/10\n","19/19 [==============================] - ETA: 0s - loss: 1.1126 - accuracy: 0.5038 \n","Epoch 00005: val_loss did not improve from 1.07006\n","19/19 [==============================] - 724s 38s/step - loss: 1.1126 - accuracy: 0.5038 - val_loss: 1.3269 - val_accuracy: 0.4844\n","Epoch 6/10\n","19/19 [==============================] - ETA: 0s - loss: 1.0788 - accuracy: 0.5383 \n","Epoch 00006: val_loss improved from 1.07006 to 0.95707, saving model to crop_disease.h5\n","19/19 [==============================] - 725s 38s/step - loss: 1.0788 - accuracy: 0.5383 - val_loss: 0.9571 - val_accuracy: 0.5938\n","Epoch 7/10\n","19/19 [==============================] - ETA: 0s - loss: 1.0795 - accuracy: 0.5425 \n","Epoch 00007: val_loss did not improve from 0.95707\n","19/19 [==============================] - 731s 39s/step - loss: 1.0795 - accuracy: 0.5425 - val_loss: 1.0091 - val_accuracy: 0.5859\n","Epoch 8/10\n","19/19 [==============================] - ETA: 0s - loss: 1.0814 - accuracy: 0.5593 \n","Epoch 00008: val_loss did not improve from 0.95707\n","19/19 [==============================] - 722s 38s/step - loss: 1.0814 - accuracy: 0.5593 - val_loss: 0.9961 - val_accuracy: 0.6016\n","Epoch 9/10\n","19/19 [==============================] - ETA: 0s - loss: 1.0478 - accuracy: 0.5744 Restoring model weights from the end of the best epoch: 6.\n","\n","Epoch 00009: val_loss did not improve from 0.95707\n","19/19 [==============================] - 730s 38s/step - loss: 1.0478 - accuracy: 0.5744 - val_loss: 0.9890 - val_accuracy: 0.6250\n","Epoch 00009: early stopping\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"mkIt-hcf05TN"},"execution_count":null,"outputs":[]}]}